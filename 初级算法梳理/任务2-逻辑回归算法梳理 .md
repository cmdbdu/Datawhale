# 逻辑回归和线性回归的联系与区别
> 联系
>> 1.都是一种通过最小化预测值与实际结果值之间的差距，而得到输入特征之间的最佳组合方式的一类算法。

> 区别
>> 1.线性回归要求因变量必须是连续性数据变量；逻辑回归要求因变量必须是分类变量，二分类或者多分类的
>> 2.线性回归主要用来解决连续值预测的问题;逻辑回归用来解决分类的问题，输出的属于某个类别的概率，工业界经常会用逻辑回归来做排序。

# 逻辑回归的原理


# 逻辑回归损失函数推导及优化

# 正则化与模型评估指标

# 逻辑回归的优缺点
> 优点
>> 1.高效
>> 2.计算量小
>> 3.容易理解
>> 4.易于调整（或不需调整）
>> 5.输出较准确
>> 6.易于实现

> 缺点
>> 1.不能解决非线性问题
>> 2.依赖正确的数据
>> 3.容易过拟合

# 样本不均衡问题解决办法
> 1. 采样
>> 法是通过对训练集进行处理使其从不平衡的数据集变成平衡的数据集，在大部分情况下会对最终的结果带来提升。
> 2.数据合成
>> 数据合成方法是利用已有样本生成更多样本。
> 3.加权
> 4. 一分类
>> 
# sklearn 参数